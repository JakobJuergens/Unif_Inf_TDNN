\section{Useful Results}
\hrule

\begin{lem}[Kernel of TDNN Estimator - Adapted from Lemma 8 of \citet{demirkaya_optimal_2024}]\label{lem:dem8}\mbox{}\\*
	The kernel of the TDNN estimator takes the following form.
	\begin{equation}
		\begin{aligned}
			h_{s_1, s_2}\left(\mathbf{x}; D\right)
			 & = w_{1}^{*}\left[\binom{s_2}{s_1}^{-1}\sum_{\ell \in L_{s_2, s_1}} h_{s_1}\left(\mathbf{x}; \mathbf{D}_{\ell}\right)\right] + w_{2}^{*} h_{s_2}\left(\mathbf{x}; D\right) \\
			 & = w_{1}^{*} \tilde{\mu}_{s_1}\left(\mathbf{x}; D\right) + w_{2}^{*} h_{s_2}\left(\mathbf{x}; D\right)                                                                     \\
		\end{aligned}
	\end{equation}
	As this expression shows, the kernel for the TDNN estimator is of order $s_2 > s_1$.
\end{lem}
\hrule

\begin{lem}[\citet{demirkaya_optimal_2024} - Lemma 12]\label{lem:dem12}\mbox{}\\*
	Let $D = \{\mathbf{Z}_1, \dotsc, \mathbf{Z}_s\}$ an i.i.d. sample drawn from $P$.
	The indicator functions $\kappa\left(\mathbf{x}; \mathbf{Z}_i, D\right)$ satisfy the following properties.
	\begin{enumerate}
		\item For any $i \neq j$, we have $\kappa\left(\mathbf{x}; \mathbf{Z}_i, D\right) \kappa\left(\mathbf{x}; \mathbf{Z}_j, D\right)=0$ with probability one;
		\item $\sum_{i=1}^{s} \kappa\left(\mathbf{x}; \mathbf{Z}_i, D\right)=1$;
		\item $\forall i \in [s]: \quad \mathbb{E}_{1:s}\left[\kappa\left(\mathbf{x}; \mathbf{Z}_i, D\right)\right]=s^{-1}$
		\item $\mathbb{E}_{2: s}\left[\kappa\left(\mathbf{x}; \mathbf{Z}_1, D\right)\right]=\left\{1-\varphi\left(B\left(\mathbf{x},\left\|\mathbf{X}_1-\mathbf{x}\right\|\right)\right)\right\}^{s-1}$
	\end{enumerate}
	Here $\mathbb{E}_{i: s}$ denotes the expectation with respect to $\left\{\mathbf{Z}_i, \mathbf{Z}_{i+1}, \cdots, \mathbf{Z}_s\right\}$.
	Furthermore, $\varphi$ denotes the probability measure on $\mathbb{R}^{d}$ induced by the random vector $\mathbf{X}$.
\end{lem}

\hrule

\begin{lem}[\citet{demirkaya_optimal_2024} - Lemma 13]\label{lem:dem13}\mbox{}\\*
	For any $L^1$ function $f$ that is continuous at $\mathbf{x}$, it holds that
	\begin{equation}
		\lim _{s \rightarrow \infty} \E_1\left[f\left(\mathbf{X}_1\right) s \E_{2: s}\left[\kappa(\mathbf{x}; \mathbf{Z}_1, D)\right]\right]
		= f(\mathbf{x}).
	\end{equation}
\end{lem}

\hrule

\begin{lem}[\citet{peng_bias_2021} - Lemma 1]\label{lem:peng1}\mbox{}\\*
	Suppose that $\sum X_i^2 \xrightarrow{p} 1, \sum \mathbb{E}\left[X_i^2\right] \rightarrow 1$, and $\sum_{i=1}^n \mathbb{E}\left[Y_i^2\right] \rightarrow 0$, then
	\begin{equation}
		\sum\left[X_i+Y_i\right]^2 \xrightarrow{p} 1 \quad \text { and } \mathbb{E}\left[\sum\left(X_i+Y_i\right)^2\right] \rightarrow 1.
	\end{equation}
\end{lem}

\hrule

\begin{lem}[Honesty of the DNN/TDNN Estimators]\label{lem:honesty}\mbox{}\\*
	The DNN and TDNN estimator kernels $\kappa\left(\cdot, \cdot, D_{\ell}\right)$ are Honest in the sense of \citet{wager_estimation_2018}.
	\begin{equation*}
		\kappa\left(\mathbf{x}, \mathbf{X}_i, D_{\ell}\right) \indep Y_i \mid \mathbf{X}_i, D_{\ell,-i},
	\end{equation*}
	where $\indep$ denotes conditional independence and $D_{\ell,-i} = \{\mathbf{Z}_l \, | \, l \in \ell \backslash \{i\}\}$.
\end{lem}