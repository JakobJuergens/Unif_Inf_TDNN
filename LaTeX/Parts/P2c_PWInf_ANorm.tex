\subsection{Asymptotic Normality Results}
\hrule

Before going on to the proofs for the theorems showing asymptotic normality, we introduce some notation.
First, we observe that the Neyman-orthogonal score function of interest $m$ is linear and can be decomposed as follows.
\begin{equation}
    \begin{aligned}
        m\left(Z_{i}; \operatorname{CATE}(x), \mu, \pi\right)
		  & = \underbrace{\mu_1\left(X_{i}\right) - \mu_0\left(X_{i}\right) + \beta\left(W_{i}, X_{i}\right)\left(Y_{i} - \mu_{W_{i}}\left(X_{i}\right)\right)}_{\psi^{b}\left(Z_{i}; \mu, \pi\right)} 
          - \operatorname{CATE}\left(x\right)\\
          %
          & = - \operatorname{CATE}\left(x\right) + \psi^{b}\left(Z_{i}; \mu, \pi\right)
    \end{aligned}
\end{equation}  

\subsection{NPR-Estimators - Asymptotic Normality}
\hrule

\subsection{CATE-Estimators - Asymptotic Normality}
\hrule
Recall the decomposition of the DNN-DML2 estimator introduced in equation \ref{eq:DNNDML2_Decomp}.
\begin{equation}
    \begin{aligned}
        \widehat{\operatorname{CATE}}\left(x; \mathbf{D}\right)
        & = \underbrace{\E_{D}\left[\widehat{\operatorname{CATE}}\left(x; \mathbf{D}\right)\right]}_{\text{Centering-Term}}
        + \underbrace{\frac{s}{n} \sum_{i = 1}^{n} \left[\chi_{s,0}^{(1)}\left(x; Z_{i}\right) + R_{1}\left(x; Z_{i}\right)  \right]}_{\text{Pseudo-H\'ajek-Projection}}\\
        & \quad \quad + \underbrace{\sum_{j = 2}^{s} \binom{s}{j} \binom{n}{j}^{-1}\sum_{\ell \in L_{n,j}} \left[\chi_{s,0}^{(c)}\left(x; \mathbf{D}_{\ell}\right) + R_{j}\left(x; \mathbf{D}_{\ell}\right)\right]}_{\text{Pseudo-H\'ajek-Residual}}
    \end{aligned}
\end{equation}
where we have the following definition from Equation \ref{eq:DNNDML2_ResidDecomp}.
\begin{equation}
    \begin{aligned}
        \chi_{s}^{(c)}\left(x; \mathbf{D}_{\ell}, \hat{\mu}, \hat{\pi}\right)
        & = \chi_{s,0}^{(c)}\left(x; \mathbf{D}_{\ell}\right) + \underbrace{\chi_{s}^{(c)}\left(x; \mathbf{D}_{\ell}, \hat{\mu}, \hat{\pi}\right) - \chi_{s,0}^{(c)}\left(x; \mathbf{D}_{\ell}\right)}_{R_{c}\left(x; \mathbf{D}_{\ell}\right)}
    \end{aligned}
\end{equation}

\hrule

\begin{lem}[Consistency of the DNN-DML2 CATE Estimator]\label{lem:DNNDML2_consist}\mbox{}\\*
    
\end{lem}

\begin{proof}[Proof of Lemma \ref{lem:DNNDML2_consist}]\mbox{}\\*
    
\end{proof}

\hrule

\begin{lem}[Behavior of the residual terms $R_{j}\left(x; \mathbf{D}_{\ell}\right)$]\label{lem:residual_beh}
    
\end{lem}

\begin{proof}[Proof of Lemma \ref{lem:residual_beh}]\mbox{}\\*
    \begin{equation}
        \begin{aligned}
            R_{1}\left(x; Z\right)
            & = \chi_{s}^{(1)}\left(x; Z, \hat{\mu}, \hat{\pi}\right) - \chi_{s,0}^{(1)}\left(x; Z\right) \\
            %
            & = \vartheta_{s}^{1}\left(x; Z, \hat{\mu}, \hat{\pi}\right)
            - \E_{D}\left[\chi_{s}(x; \mathbf{D}, \hat{\mu}, \hat{\pi})\right]
            - \vartheta_{s,0}^{1}\left(x; Z\right) 
            + \E_{D}\left[\chi_{s,0}\left(x; \mathbf{D}\right)\right]\\
            %
            & = \E_{D}\left[\chi_{s}(x; \mathbf{D}, \hat{\mu}, \hat{\pi}) \, \middle| \, Z_1 = Z \right]
             - \E_{D}\left[\chi_{s}(x; \mathbf{D}, \hat{\mu}, \hat{\pi})\right]
            - \E_{D}\left[\chi_{s,0}(x; \mathbf{D}) \, \middle| \, Z_1 = Z \right]
            + \E_{D}\left[\chi_{s,0}\left(x; \mathbf{D}\right)\right]\\
        \end{aligned}
    \end{equation}    

    \hrule 

    Second Idea:
    \begin{equation}
        \begin{aligned}
            \mathfrak{R}_{1}\left(x; \mathbf{D}\right)
            & = \frac{1}{n}\sum_{i = 1}^{n} R_{1}\left(x; Z_{i}\right) \\
            %
            & = \E_{D}\left[\chi_{s,0}\left(x; \mathbf{D}\right)\right]
            - \E_{D}\left[\chi_{s}(x; \mathbf{D}, \hat{\mu}, \hat{\pi})\right]
            + \frac{1}{n}\sum_{i = 1}^{n}\left(\E_{D}\left[\chi_{s}(x; \mathbf{D}, \hat{\mu}, \hat{\pi}) \, \middle| \, Z_1 = Z_i \right]
            - \E_{D}\left[\chi_{s,0}(x; \mathbf{D}) \, \middle| \, Z_1 = Z_i \right]\right)
        \end{aligned}
    \end{equation}
     Next, fix an arbitrary $k \in [K]$, an arbitrary fold from the cross-fitting procedure and let $\hat{\mu}_{k}$ and $\hat{\pi}_{k}$ denote the nuisance parameter estimates calculated on the complement of that fold.
    \begin{equation}
        \begin{aligned}
            \mathfrak{R}_{1,k}\left(x; \mathbf{D}\right)
            & = \E_{D}\left[\chi_{s,0}\left(x; \mathbf{D}\right)\right]
            - \E_{D}\left[\chi_{s}(x; \mathbf{D}, \hat{\mu}_k, \hat{\pi}_k)\right]\\
            & \quad + \frac{1}{m}\sum_{i \in \mathcal{I}_{k}}\left(\E_{D}\left[\chi_{s}(x; \mathbf{D}, \hat{\mu}_k, \hat{\pi}_k) \, \middle| \, Z_1 = Z_i \right]
            - \E_{D}\left[\chi_{s,0}(x; \mathbf{D}) \, \middle| \, Z_1 = Z_i \right]\right)
        \end{aligned}
    \end{equation}
\end{proof}

\hrule